{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick and Place Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will use the feature library to recognize, pick and then place objects set on a table below the hand. \n",
    "We assume the hand to be placed approximately 20cm above the objects of interest (1). If everything goes right, you should expect a point cloud as shown in (2), a segmentation result as in (3) and a resulting grasp as shown in (4).\n",
    "\n",
    "<img src=\"pick_and_place.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up robot please wait...\n",
      "Robot Ready!\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import rmlib\n",
    "rm = rmlib.RMLib()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Feature Library\n",
    "\n",
    "A <i>feature</i> is a datastructure that describes the sequence of image processing steps (`capture_process_list`) and their parameters that the SmartHand needs to perform to find a specific object. Features can be created with Robotic Materials' feature editor to differentiate arbitrary objects, or a \"default feature\" can be used that works with most unknown objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library Features:\n",
      "default:\n",
      "       capture_process_list :\n",
      "              0 :\n",
      "              descriptor  =  downsample\n",
      "              leaf_size  =  0.003\n",
      "              1 :\n",
      "              descriptor  =  remove_plane\n",
      "              plane_tol  =  0.005\n",
      "              2 :\n",
      "              descriptor  =  dbscan\n",
      "              min_samples  =  10\n",
      "              search_radius  =  0.01\n",
      "              3 :\n",
      "              cluster_size  =  [40, 10000000]\n",
      "              descriptor  =  filter_by_size\n",
      "              max_clouds_returned  =  100\n",
      "              x_axis  =  [0.008, 0.2]\n",
      "              y_axis  =  [0.008, 0.1]\n",
      "              z_axis  =  [0.006, 0.1]\n",
      "              4 :\n",
      "              descriptor  =  sort_clouds_height\n",
      "              high_to_low  =  True\n",
      "              5 :\n",
      "              descriptor  =  find_grasp\n",
      "              rotate_z  =  True\n",
      "       view_distance  =  0.15\n"
     ]
    }
   ],
   "source": [
    "#Load in the feature library to use default feature or features created in the feature editor (coming soon).\n",
    "lib = rm.load_feature_lib()\n",
    "\n",
    "# Use print_feature_lib() to print a readable version of the feature lib\n",
    "rm.print_feature_lib(lib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the feature is found by performing a downsampling step, removing the table plane, a segmentation step, a filter based on object size (<code>x_axis, y_axis, z_axis</code>), then sorts objects by their height (<code>high_to_low = True</code>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select a feature from the feature library\n",
    "your_feature = 'default'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Define Waypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><center><h3>Warning: make sure the robot can move safely between the start_point and the drop_point</h3><i></center>\n",
    "    \n",
    "We will now define a couple of way points that will serve the robot as starting and drop-off locations. More complex environments might require the robot to sweep the workspace or generate a drop-off location based on what is already in a container, e.g., for palletizing. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Move the smarthand to the view distance specified by your feature as shown in the picture above. The default feature uses a view distance of 0.15m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Align Gripper, use this function to align the gripper to the nearest axis\n",
    "rm.align_gripper_with_axis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Save waypoint\n",
    "start_point = rm.get_tcp_pose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. # Move the smarthand to your desired object drop point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Align Gripper, use this function to align the gripper to the nearest axis\n",
    "rm.align_gripper_with_axis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Save waypoint\n",
    "drop_point = rm.get_tcp_pose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Feature\n",
    "\n",
    "To find a feature and a potential grasp, the robot will first move to `start_point` and open the gripper. (If the gripper is closed, the robot will not have its entire field of view at its disposal and might miss part of the workspace.) The `find_feature` function allows you to specify, which of the steps in the `capture_process_list` (Section <i>Select Feature</i>) should be displayed to the user. In this example, we selected `c` to view the raw capture, `2` to view the dbscan segmented cloud, and `5` to view the grasp found.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move to start point\n",
    "rm.movej(start_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open gripper\n",
    "rm.open_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capture Cloud Output:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fadfd14439ef44d29a4b184a6648198e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.6, fov=90.0, position=(-0.00534798205755243, 0.4592661888557138, 0.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819c866f1b4844ac88f8ab251dcfd003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.001, max=0.01, step=1e-05), Label(value='Backgr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment Cloud DBScan Output:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e324e5782be7438e8ef9bc8e23283a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.6, fov=90.0, position=(-0.0007770934366057768, 0.2224529075699343, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e5d6347ffe4fc8b856c10db5924741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.001, max=0.01, step=1e-05), Label(value='Backgr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab809be84214b12ae417dc5732e7fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Renderer(camera=PerspectiveCamera(aspect=1.6, fov=90.0, position=(-0.00491719346796557, 0.44811141964169116, 0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25eb153396e34e3d92a28a83feee517c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Point size:'), FloatSlider(value=0.001, max=0.01, step=1e-05), Label(value='Backgr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run find_feature to get a capture and run the process list\n",
    "grasps = rm.find_feature(lib[your_feature], output=['c', '2', '5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grasps\n",
    "\n",
    "A `grasp` is a datastructure consisting of a robot pose and a grasp width. The grasp generator returns a list of grasps that are sorted based on the specific grasp generator that has been selected in the `capture_process_list`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pose:\n",
      "[[-9.98982078e-01 -4.51088361e-02 -1.77614306e-05 -1.34612622e-01]\n",
      " [-4.51088007e-02  9.98980622e-01  1.70678207e-03 -3.97567255e-01]\n",
      " [-5.92476277e-05  1.70584590e-03 -9.99998543e-01  2.77650075e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "\n",
      "Grasp Width:\n",
      "0.02499535776717239\n"
     ]
    }
   ],
   "source": [
    "# The returned grasp is a nested list of grasps, by selecting index 0 we can view the first grasp returned.\n",
    "grasp = grasps[0]\n",
    "# A grasp consists of a pose (4x4 homogeneous transformation matrix) and a grasp width (float)\n",
    "print('Pose:')\n",
    "print(grasp[0])\n",
    "print()\n",
    "print('Grasp Width:')\n",
    "print(grasp[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick Object\n",
    "\n",
    "In order to safely grasp an object, we first will need to move to a safe position just above the grasp pose. We then set the gripper width to the size returned by the grasp generator, and finally move to the grasp pose, close the gripper and return to the drop-off location after revisiting the safe pre-grasp pose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move to grasp pose approach\n",
    "rm.move_tcp_over_pose(grasp[0], distance=0.15, rotate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set gripper width\n",
    "rm.set_gripper_width(grasp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move to pose\n",
    "rm.movel(grasp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Close gripper\n",
    "rm.close_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move back to grasp pose approach\n",
    "rm.move_tcp_over_pose(grasp[0], distance=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move to drop point\n",
    "rm.movej(drop_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open gripper\n",
    "rm.open_gripper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
