{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>ML Random Forest Example</h1>\n",
    "This example demonstrates classification of time-series data from the force-torque sensor to detect grasping failure. The data is taken from the <a href=\"https://archive.ics.uci.edu/ml/datasets/Robot+Execution+Failures\">Robot execution failures</a> dataset. It consists of 87 labeled instances of sequences of 15 F/T measurements and class labels.\n",
    "\n",
    "The data is parsed into a pandas dataframe, broken into training and test set, and run through a random forest regressor from sklearn. \n",
    "\n",
    "<br>\n",
    "This example has been adapted from the very <a href=\"https://towardsdatascience.com/random-forest-in-python-24d0893d51c0\">nice introduction</a> to Random Forest regression by William Koehrsen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2b9a7152be94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Import ML tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Import data processing tools\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib ipympl\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Import ML tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Import tools needed for visualization\n",
    "from IPython.display import Image, display\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of time series of 6-DoF force/torque measurements that are labeled with success ('normal') or failure ('obstruction', 'collision', 'fr_collision'). The raw data can be inspected <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/robotfailure-mld/lp1.data\">here</a> and needs to be converted in table format. <br><br>\n",
    "The code for parsing the data has been adopted from a <a href=\"https://tsfresh.readthedocs.io/en/latest/_modules/tsfresh/examples/robot_execution_failures.html\">tsfresh tutorial</a>. It proceeds by reading the data file line by line and storing an entire time series in a single row. Sucess and the various failure modes are coded as a boolean value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    id_to_target = {}\n",
    "    df_rows = []\n",
    "    df_block = []\n",
    "\n",
    "    with open('data/lp1.data') as f:\n",
    "        cur_id = 0\n",
    "        time = 0\n",
    "\n",
    "        for line in f.readlines():\n",
    "            # New sample --> increase id, reset time and determine target\n",
    "            if line[0] not in ['\\t', '\\n']:               \n",
    "                time = 0\n",
    "                #id_to_target[cur_id] = line.strip()\n",
    "                id_to_target[cur_id] = (line.strip()=='normal')\n",
    "                if(df_block): \n",
    "                    df_rows.append(np.array(df_block).reshape(1,90)[0].tolist())\n",
    "                df_block = []\n",
    "                cur_id += 1\n",
    "            # Data row --> split and convert values, create complete df row\n",
    "            elif line[0] == '\\t':\n",
    "                values = list(map(int, line.split('\\t')[1:]))\n",
    "                #df_rows.append([cur_id, time] + values)\n",
    "                df_block.append(values)\n",
    "                time += 1\n",
    "        df_rows.append(np.array(df_block).reshape(1,90)[0].tolist())\n",
    "\n",
    "    columns=[]\n",
    "    for i in range(0,15):\n",
    "        columns=columns+['F_x'+str(i), 'F_y'+str(i), 'F_z'+str(i), 'T_x'+str(i), 'T_y'+str(i), 'T_z'+str(i)]\n",
    "    \n",
    "    df = pd.DataFrame(df_rows, columns=columns) # Store all data in a Pandas dataframe\n",
    "    y = pd.Series(id_to_target) # Store all class labels in a Pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4add252522c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "1    True\n",
       "2    True\n",
       "3    True\n",
       "4    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using sklearn's RandomForestRegressor using standard parameters. 75% of the data is used for training and 25% as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=y\n",
    "features=np.array(df)\n",
    "feature_list=list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 100, max_depth =15, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=15,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(train_features,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.round(rf.predict(test_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Results</h2>\n",
    "We can now compare the predictions made by the random forest with the known labels from the test set and calculate the percentage of errorneous predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = abs(predictions-test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  0.0 %\n"
     ]
    }
   ],
   "source": [
    "print('Error: ',sum(errors)/len(test_labels)*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Using machine learning for system analysis</h1>\n",
    "\n",
    "A byproduct of the training process are statistical measures how predictive the different attributes of the\n",
    "problem set are. The code below retrieves this information from the classifier and sorts them after their importance.\n",
    "<br><br>\n",
    "This information can be used to train classifiers that are computationally more efficient or to better understand what is actually \n",
    "going on in the robotic system. In this example, we learn that force measurements in z-direction are most predictive to distinguish a failed from a normal grasp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: F_z0                 Importance: 0.25\n",
      "Variable: F_z2                 Importance: 0.17\n",
      "Variable: F_z1                 Importance: 0.15\n",
      "Variable: T_x2                 Importance: 0.04\n",
      "Variable: F_z8                 Importance: 0.04\n",
      "Variable: T_x6                 Importance: 0.03\n",
      "Variable: F_x7                 Importance: 0.02\n",
      "Variable: F_x8                 Importance: 0.02\n",
      "Variable: F_z11                Importance: 0.02\n",
      "Variable: F_x0                 Importance: 0.01\n",
      "Variable: F_y0                 Importance: 0.01\n",
      "Variable: T_y0                 Importance: 0.01\n",
      "Variable: F_x1                 Importance: 0.01\n",
      "Variable: F_y1                 Importance: 0.01\n",
      "Variable: F_x2                 Importance: 0.01\n",
      "Variable: T_y2                 Importance: 0.01\n",
      "Variable: F_x3                 Importance: 0.01\n",
      "Variable: T_x3                 Importance: 0.01\n",
      "Variable: T_y3                 Importance: 0.01\n",
      "Variable: F_x4                 Importance: 0.01\n",
      "Variable: T_x4                 Importance: 0.01\n",
      "Variable: F_z6                 Importance: 0.01\n",
      "Variable: F_y7                 Importance: 0.01\n",
      "Variable: T_y7                 Importance: 0.01\n",
      "Variable: F_z10                Importance: 0.01\n",
      "Variable: F_x12                Importance: 0.01\n",
      "Variable: F_z12                Importance: 0.01\n",
      "Variable: F_z13                Importance: 0.01\n",
      "Variable: T_x0                 Importance: 0.0\n",
      "Variable: T_z0                 Importance: 0.0\n",
      "Variable: T_x1                 Importance: 0.0\n",
      "Variable: T_y1                 Importance: 0.0\n",
      "Variable: T_z1                 Importance: 0.0\n",
      "Variable: F_y2                 Importance: 0.0\n",
      "Variable: T_z2                 Importance: 0.0\n",
      "Variable: F_y3                 Importance: 0.0\n",
      "Variable: F_z3                 Importance: 0.0\n",
      "Variable: T_z3                 Importance: 0.0\n",
      "Variable: F_y4                 Importance: 0.0\n",
      "Variable: F_z4                 Importance: 0.0\n",
      "Variable: T_y4                 Importance: 0.0\n",
      "Variable: T_z4                 Importance: 0.0\n",
      "Variable: F_x5                 Importance: 0.0\n",
      "Variable: F_y5                 Importance: 0.0\n",
      "Variable: F_z5                 Importance: 0.0\n",
      "Variable: T_x5                 Importance: 0.0\n",
      "Variable: T_y5                 Importance: 0.0\n",
      "Variable: T_z5                 Importance: 0.0\n",
      "Variable: F_x6                 Importance: 0.0\n",
      "Variable: F_y6                 Importance: 0.0\n",
      "Variable: T_y6                 Importance: 0.0\n",
      "Variable: T_z6                 Importance: 0.0\n",
      "Variable: F_z7                 Importance: 0.0\n",
      "Variable: T_x7                 Importance: 0.0\n",
      "Variable: T_z7                 Importance: 0.0\n",
      "Variable: F_y8                 Importance: 0.0\n",
      "Variable: T_x8                 Importance: 0.0\n",
      "Variable: T_y8                 Importance: 0.0\n",
      "Variable: T_z8                 Importance: 0.0\n",
      "Variable: F_x9                 Importance: 0.0\n",
      "Variable: F_y9                 Importance: 0.0\n",
      "Variable: F_z9                 Importance: 0.0\n",
      "Variable: T_x9                 Importance: 0.0\n",
      "Variable: T_y9                 Importance: 0.0\n",
      "Variable: T_z9                 Importance: 0.0\n",
      "Variable: F_x10                Importance: 0.0\n",
      "Variable: F_y10                Importance: 0.0\n",
      "Variable: T_x10                Importance: 0.0\n",
      "Variable: T_y10                Importance: 0.0\n",
      "Variable: T_z10                Importance: 0.0\n",
      "Variable: F_x11                Importance: 0.0\n",
      "Variable: F_y11                Importance: 0.0\n",
      "Variable: T_x11                Importance: 0.0\n",
      "Variable: T_y11                Importance: 0.0\n",
      "Variable: T_z11                Importance: 0.0\n",
      "Variable: F_y12                Importance: 0.0\n",
      "Variable: T_x12                Importance: 0.0\n",
      "Variable: T_y12                Importance: 0.0\n",
      "Variable: T_z12                Importance: 0.0\n",
      "Variable: F_x13                Importance: 0.0\n",
      "Variable: F_y13                Importance: 0.0\n",
      "Variable: T_x13                Importance: 0.0\n",
      "Variable: T_y13                Importance: 0.0\n",
      "Variable: T_z13                Importance: 0.0\n",
      "Variable: F_x14                Importance: 0.0\n",
      "Variable: F_y14                Importance: 0.0\n",
      "Variable: F_z14                Importance: 0.0\n",
      "Variable: T_x14                Importance: 0.0\n",
      "Variable: T_y14                Importance: 0.0\n",
      "Variable: T_z14                Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a2d0aff7344bf194691bc095b1165a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib ipympl\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.bar(range(1,10),[a[1] for a in feature_importances[1:10]])\n",
    "plt.xticks(range(1,10), [a[0] for a in feature_importances[1:10]], rotation='vertical',fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.ylabel('Importance',fontsize=8); plt.xlabel('Variable',fontsize=8); plt.title('Variable Importances');\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
